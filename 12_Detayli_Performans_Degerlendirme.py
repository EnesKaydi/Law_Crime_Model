"""
12_Detayli_Performans_Degerlendirme.py

Bu script:
- EÄŸitilmiÅŸ XGBoost modelini yÃ¼kler
- Ceza kategorilerine gÃ¶re (Hafif/Orta/AÄŸÄ±r) performans analizi yapar
- Hata daÄŸÄ±lÄ±mlarÄ±nÄ± detaylÄ±ca inceler
- Prediction intervals (gÃ¼ven aralÄ±klarÄ±) hesaplar
- GerÃ§ek vs tahmin karÅŸÄ±laÅŸtÄ±rma tablolarÄ± oluÅŸturur
- Model baÅŸarÄ±/baÅŸarÄ±sÄ±zlÄ±k vakalarÄ±nÄ± analiz eder
- TÃ¼m sonuÃ§larÄ± SONUCLAR.md'ye kaydeder

KullanÄ±m:
    /Users/muhammedeneskaydi/PycharmProjects/LAW/.venv/bin/python 12_Detayli_Performans_Degerlendirme.py

Notlar:
- Bu adÄ±m, tez savunmasÄ± iÃ§in detaylÄ± performans metrikleri saÄŸlar
- Kategorik analiz, modelin hangi vaka tiplerinde baÅŸarÄ±lÄ±/baÅŸarÄ±sÄ±z olduÄŸunu gÃ¶sterir
"""

import os
import pickle
from datetime import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# --- Ayarlar ---
BASE_DIR = "/Users/muhammedeneskaydi/PycharmProjects/LAW"
MODEL_DATA_DIR = os.path.join(BASE_DIR, "model_data")
MODEL_DIR = os.path.join(BASE_DIR, "outputs", "model")
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs", "performance")
SONUCLAR_PATH = os.path.join(BASE_DIR, "SONUCLAR.md")

os.makedirs(OUTPUT_DIR, exist_ok=True)

# Plot ayarlarÄ±
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (14, 8)
plt.rcParams['font.size'] = 10

print("=" * 80)
print("ADIM 9: DETAYLI MODEL PERFORMANS DEÄERLENDÄ°RME")
print("=" * 80)

# ===== 1. MODEL VE VERÄ° YÃœKLEME =====
print("\n" + "=" * 80)
print("1. MODEL VE VERÄ° YÃœKLEME")
print("=" * 80)

print(f"\n  ğŸ“‚ Model yÃ¼kleniyor...")
model_path = os.path.join(MODEL_DIR, 'xgboost_jail_model.pkl')
with open(model_path, 'rb') as f:
    model = pickle.load(f)
print(f"  âœ… Model yÃ¼klendi: {model_path}")

print(f"\n  ğŸ“‚ Test veri seti yÃ¼kleniyor...")
X_test = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'X_test.csv'))
y_test = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'y_test.csv'))
print(f"  âœ… Test seti yÃ¼klendi: {len(X_test):,} kayÄ±t")

# Tahminler
y_test_jail = y_test['jail']
y_pred = model.predict(X_test)

print(f"\n  ğŸ¯ Tahminler yapÄ±ldÄ±")

# ===== 2. CEZA KATEGORÄ°LERÄ°NE GÃ–RE PERFORMANS =====
print("\n" + "=" * 80)
print("2. CEZA KATEGORÄ°LERÄ°NE GÃ–RE PERFORMANS ANALÄ°ZÄ°")
print("=" * 80)

# Kategoriler oluÅŸtur
def categorize_jail(val):
    if val <= 180:
        return 'Hafif (1-180 gÃ¼n)'
    elif val <= 1080:
        return 'Orta (181-1080 gÃ¼n)'
    else:
        return 'AÄŸÄ±r (1080+ gÃ¼n)'

y_test['jail_category'] = y_test_jail.apply(categorize_jail)
y_test['y_pred'] = y_pred
y_test['error'] = y_test_jail - y_pred
y_test['abs_error'] = np.abs(y_test['error'])
y_test['percent_error'] = (y_test['abs_error'] / (y_test_jail + 1)) * 100  # +1 to avoid division by zero

print(f"\n  ğŸ“Š Kategori DaÄŸÄ±lÄ±mÄ±:")
category_counts = y_test['jail_category'].value_counts().sort_index()
for cat, count in category_counts.items():
    pct = count / len(y_test) * 100
    print(f"    â€¢ {cat}: {count:,} (%{pct:.2f})")

# Kategori bazlÄ± metrikler
print(f"\n  ğŸ“Š Kategori BazlÄ± Performans Metrikleri:")

category_metrics = []
for cat in sorted(y_test['jail_category'].unique()):
    mask = y_test['jail_category'] == cat
    y_true_cat = y_test_jail[mask]
    y_pred_cat = y_pred[mask]
    
    rmse = np.sqrt(mean_squared_error(y_true_cat, y_pred_cat))
    mae = mean_absolute_error(y_true_cat, y_pred_cat)
    r2 = r2_score(y_true_cat, y_pred_cat)
    
    category_metrics.append({
        'Kategori': cat,
        'N': len(y_true_cat),
        'RMSE': rmse,
        'MAE': mae,
        'RÂ²': r2,
        'Ortalama GerÃ§ek': y_true_cat.mean(),
        'Ortalama Tahmin': y_pred_cat.mean()
    })
    
    print(f"\n    {cat}:")
    print(f"      â€¢ N: {len(y_true_cat):,}")
    print(f"      â€¢ RMSE: {rmse:.2f} gÃ¼n")
    print(f"      â€¢ MAE: {mae:.2f} gÃ¼n")
    print(f"      â€¢ RÂ²: {r2:.4f}")
    print(f"      â€¢ Ortalama GerÃ§ek: {y_true_cat.mean():.2f} gÃ¼n")
    print(f"      â€¢ Ortalama Tahmin: {y_pred_cat.mean():.2f} gÃ¼n")

# Kategori metrikleri DataFrame
category_df = pd.DataFrame(category_metrics)

# Kategori bazlÄ± performans gÃ¶rselleÅŸtirme
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# MAE by category
axes[0, 0].bar(range(len(category_df)), category_df['MAE'], color=['#2ecc71', '#f39c12', '#e74c3c'])
axes[0, 0].set_xticks(range(len(category_df)))
axes[0, 0].set_xticklabels(category_df['Kategori'], rotation=15, ha='right')
axes[0, 0].set_ylabel('MAE (gÃ¼n)', fontsize=11)
axes[0, 0].set_title('Kategori BazlÄ± Ortalama Mutlak Hata (MAE)', fontsize=12, fontweight='bold')
axes[0, 0].grid(True, alpha=0.3)
for i, v in enumerate(category_df['MAE']):
    axes[0, 0].text(i, v + 5, f'{v:.1f}', ha='center', fontweight='bold')

# RÂ² by category
axes[0, 1].bar(range(len(category_df)), category_df['RÂ²'], color=['#2ecc71', '#f39c12', '#e74c3c'])
axes[0, 1].set_xticks(range(len(category_df)))
axes[0, 1].set_xticklabels(category_df['Kategori'], rotation=15, ha='right')
axes[0, 1].set_ylabel('RÂ² Score', fontsize=11)
axes[0, 1].set_title('Kategori BazlÄ± RÂ² PerformansÄ±', fontsize=12, fontweight='bold')
axes[0, 1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[0, 1].grid(True, alpha=0.3)
for i, v in enumerate(category_df['RÂ²']):
    axes[0, 1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

# Sample distribution by category
axes[1, 0].bar(range(len(category_df)), category_df['N'], color=['#2ecc71', '#f39c12', '#e74c3c'])
axes[1, 0].set_xticks(range(len(category_df)))
axes[1, 0].set_xticklabels(category_df['Kategori'], rotation=15, ha='right')
axes[1, 0].set_ylabel('KayÄ±t SayÄ±sÄ±', fontsize=11)
axes[1, 0].set_title('Kategori BazlÄ± Veri DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)
for i, v in enumerate(category_df['N']):
    axes[1, 0].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')

# Mean prediction vs actual by category
x_pos = np.arange(len(category_df))
width = 0.35
axes[1, 1].bar(x_pos - width/2, category_df['Ortalama GerÃ§ek'], width, label='GerÃ§ek', color='#3498db')
axes[1, 1].bar(x_pos + width/2, category_df['Ortalama Tahmin'], width, label='Tahmin', color='#e67e22')
axes[1, 1].set_xticks(x_pos)
axes[1, 1].set_xticklabels(category_df['Kategori'], rotation=15, ha='right')
axes[1, 1].set_ylabel('Ortalama Jail SÃ¼resi (gÃ¼n)', fontsize=11)
axes[1, 1].set_title('Kategori BazlÄ±: GerÃ§ek vs Tahmin OrtalamalarÄ±', fontsize=12, fontweight='bold')
axes[1, 1].legend()
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
category_perf_path = os.path.join(OUTPUT_DIR, 'kategori_bazli_performans.png')
plt.savefig(category_perf_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"\n  âœ… Kategori performans grafiÄŸi kaydedildi: {category_perf_path}")

# ===== 3. HATA DAÄILIM ANALÄ°ZÄ° =====
print("\n" + "=" * 80)
print("3. HATA DAÄILIM ANALÄ°ZÄ°")
print("=" * 80)

# Hata istatistikleri
error_stats = {
    'Ortalama Hata': y_test['error'].mean(),
    'Std Hata': y_test['error'].std(),
    'Median Hata': y_test['error'].median(),
    'MAE': y_test['abs_error'].mean(),
    'Median Abs Error': y_test['abs_error'].median(),
    'Max Overestimate': y_test['error'].min(),  # Negatif = overestimate
    'Max Underestimate': y_test['error'].max(),  # Pozitif = underestimate
}

print(f"\n  ğŸ“Š Genel Hata Ä°statistikleri:")
for key, value in error_stats.items():
    print(f"    â€¢ {key}: {value:.2f} gÃ¼n")

# YÃ¼zde hata daÄŸÄ±lÄ±mÄ±
percent_error_ranges = [
    ('Â±10%', (y_test['percent_error'] <= 10).sum()),
    ('Â±25%', (y_test['percent_error'] <= 25).sum()),
    ('Â±50%', (y_test['percent_error'] <= 50).sum()),
    ('Â±100%', (y_test['percent_error'] <= 100).sum()),
    ('>100%', (y_test['percent_error'] > 100).sum()),
]

print(f"\n  ğŸ“Š YÃ¼zdesel Hata DaÄŸÄ±lÄ±mÄ±:")
for range_name, count in percent_error_ranges:
    pct = count / len(y_test) * 100
    print(f"    â€¢ {range_name}: {count:,} (%{pct:.2f})")

# Hata daÄŸÄ±lÄ±m gÃ¶rseli
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Error histogram
axes[0, 0].hist(y_test['error'], bins=100, edgecolor='black', alpha=0.7, color='#3498db')
axes[0, 0].axvline(x=0, color='red', linestyle='--', lw=2, label='SÄ±fÄ±r Hata')
axes[0, 0].set_xlabel('Hata (GerÃ§ek - Tahmin) [gÃ¼n]', fontsize=11)
axes[0, 0].set_ylabel('Frekans', fontsize=11)
axes[0, 0].set_title('Hata DaÄŸÄ±lÄ±mÄ± (Error Distribution)', fontsize=12, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Absolute error histogram
axes[0, 1].hist(y_test['abs_error'], bins=100, edgecolor='black', alpha=0.7, color='#e67e22')
axes[0, 1].axvline(x=y_test['abs_error'].mean(), color='red', linestyle='--', lw=2, label=f'MAE: {y_test["abs_error"].mean():.1f}')
axes[0, 1].set_xlabel('Mutlak Hata (Absolute Error) [gÃ¼n]', fontsize=11)
axes[0, 1].set_ylabel('Frekans', fontsize=11)
axes[0, 1].set_title('Mutlak Hata DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Percent error histogram (trimmed at 200% for visibility)
percent_error_trimmed = y_test['percent_error'].clip(upper=200)
axes[1, 0].hist(percent_error_trimmed, bins=100, edgecolor='black', alpha=0.7, color='#9b59b6')
axes[1, 0].set_xlabel('YÃ¼zdesel Hata (%) [maksimum 200%]', fontsize=11)
axes[1, 0].set_ylabel('Frekans', fontsize=11)
axes[1, 0].set_title('YÃ¼zdesel Hata DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Percent error ranges bar plot
range_names = [r[0] for r in percent_error_ranges]
range_counts = [r[1] for r in percent_error_ranges]
axes[1, 1].bar(range(len(range_names)), range_counts, color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c', '#95a5a6'])
axes[1, 1].set_xticks(range(len(range_names)))
axes[1, 1].set_xticklabels(range_names)
axes[1, 1].set_ylabel('KayÄ±t SayÄ±sÄ±', fontsize=11)
axes[1, 1].set_title('YÃ¼zdesel Hata AralÄ±klarÄ±', fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)
for i, v in enumerate(range_counts):
    pct = v / len(y_test) * 100
    axes[1, 1].text(i, v + 500, f'{v:,}\n({pct:.1f}%)', ha='center', fontweight='bold')

plt.tight_layout()
error_dist_path = os.path.join(OUTPUT_DIR, 'hata_dagilim_analizi.png')
plt.savefig(error_dist_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"  âœ… Hata daÄŸÄ±lÄ±m grafiÄŸi kaydedildi: {error_dist_path}")

# ===== 4. EN Ä°YÄ° VE EN KÃ–TÃœ TAHMÄ°NLER =====
print("\n" + "=" * 80)
print("4. EN Ä°YÄ° VE EN KÃ–TÃœ TAHMÄ°NLER ANALÄ°ZÄ°")
print("=" * 80)

# En iyi tahminler (en dÃ¼ÅŸÃ¼k mutlak hata)
best_predictions = y_test.nsmallest(10, 'abs_error')[['jail', 'y_pred', 'error', 'abs_error', 'jail_category']]
print(f"\n  ğŸ† EN Ä°YÄ° 10 TAHMÄ°N (En DÃ¼ÅŸÃ¼k Mutlak Hata):")
print(best_predictions.to_string(index=False))

# En kÃ¶tÃ¼ tahminler (en yÃ¼ksek mutlak hata)
worst_predictions = y_test.nlargest(10, 'abs_error')[['jail', 'y_pred', 'error', 'abs_error', 'jail_category']]
print(f"\n  âŒ EN KÃ–TÃœ 10 TAHMÄ°N (En YÃ¼ksek Mutlak Hata):")
print(worst_predictions.to_string(index=False))

# En Ã§ok overestimate (tahmin > gerÃ§ek)
overestimate = y_test[y_test['error'] < 0].nsmallest(5, 'error')[['jail', 'y_pred', 'error', 'jail_category']]
print(f"\n  â¬†ï¸ EN FAZLA OVERESTIMATE (Tahmin > GerÃ§ek):")
if len(overestimate) > 0:
    print(overestimate.to_string(index=False))
else:
    print("    (Yok)")

# En Ã§ok underestimate (tahmin < gerÃ§ek)
underestimate = y_test[y_test['error'] > 0].nlargest(5, 'error')[['jail', 'y_pred', 'error', 'jail_category']]
print(f"\n  â¬‡ï¸ EN FAZLA UNDERESTIMATE (Tahmin < GerÃ§ek):")
if len(underestimate) > 0:
    print(underestimate.to_string(index=False))
else:
    print("    (Yok)")

# ===== 5. PREDICTION CONFIDENCE INTERVALS =====
print("\n" + "=" * 80)
print("5. PREDICTION CONFIDENCE INTERVALS (GÃ¼ven AralÄ±klarÄ±)")
print("=" * 80)

# Basit gÃ¼ven aralÄ±ÄŸÄ±: tahmin Â± 1.96*MAE (95% CI yaklaÅŸÄ±mÄ±)
mae_overall = y_test['abs_error'].mean()
ci_95 = 1.96 * mae_overall

print(f"\n  ğŸ“Š 95% GÃ¼ven AralÄ±ÄŸÄ± (BasitleÅŸtirilmiÅŸ):")
print(f"    â€¢ MAE: {mae_overall:.2f} gÃ¼n")
print(f"    â€¢ 95% CI: Â±{ci_95:.2f} gÃ¼n")
print(f"    â€¢ Yorum: Tahminlerin %95'i, gerÃ§ek deÄŸerden Â±{ci_95:.0f} gÃ¼n iÃ§inde")

# Kategori bazlÄ± gÃ¼ven aralÄ±klarÄ±
print(f"\n  ğŸ“Š Kategori BazlÄ± 95% GÃ¼ven AralÄ±klarÄ±:")
for cat in sorted(y_test['jail_category'].unique()):
    mask = y_test['jail_category'] == cat
    mae_cat = y_test.loc[mask, 'abs_error'].mean()
    ci_cat = 1.96 * mae_cat
    print(f"    â€¢ {cat}: Â±{ci_cat:.2f} gÃ¼n")

# ===== 6. Ã–ZET TABLO KAYDETME =====
print("\n" + "=" * 80)
print("6. Ã–ZET TABLO KAYDETME")
print("=" * 80)

# Kategori metrikleri CSV
category_df.to_csv(os.path.join(OUTPUT_DIR, 'kategori_metrikleri.csv'), index=False)
print(f"  âœ… Kategori metrikleri kaydedildi: kategori_metrikleri.csv")

# En iyi/kÃ¶tÃ¼ tahminler CSV
best_predictions.to_csv(os.path.join(OUTPUT_DIR, 'en_iyi_tahminler.csv'), index=False)
worst_predictions.to_csv(os.path.join(OUTPUT_DIR, 'en_kotu_tahminler.csv'), index=False)
print(f"  âœ… En iyi/kÃ¶tÃ¼ tahminler kaydedildi")

# ===== 7. SONUCLAR.MD GÃœNCELLEME =====
print("\n" + "=" * 80)
print("7. SONUCLAR.MD GÃœNCELLEME")
print("=" * 80)

now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

md_lines = []
md_lines.append(f"\n## ADIM 9: DETAYLI MODEL PERFORMANS DEÄERLENDÄ°RME âœ…\n")
md_lines.append(f"**Tarih:** {now}\n\n")

md_lines.append("### ğŸ“Š Kategori BazlÄ± Performans\n")
md_lines.append("| Kategori | N | RMSE (gÃ¼n) | MAE (gÃ¼n) | RÂ² | Ort. GerÃ§ek | Ort. Tahmin |")
md_lines.append("|----------|---|------------|-----------|-----|-------------|-------------|")
for _, row in category_df.iterrows():
    md_lines.append(f"| {row['Kategori']} | {row['N']:,} | {row['RMSE']:.2f} | {row['MAE']:.2f} | {row['RÂ²']:.4f} | {row['Ortalama GerÃ§ek']:.2f} | {row['Ortalama Tahmin']:.2f} |")
md_lines.append("\n")

md_lines.append("### ğŸ” Hata DaÄŸÄ±lÄ±m Ä°statistikleri\n")
md_lines.append("```")
for key, value in error_stats.items():
    md_lines.append(f"{key}: {value:.2f} gÃ¼n")
md_lines.append("```\n")

md_lines.append("### ğŸ“Š YÃ¼zdesel Hata DaÄŸÄ±lÄ±mÄ±\n")
md_lines.append("| Hata AralÄ±ÄŸÄ± | KayÄ±t SayÄ±sÄ± | Oran |")
md_lines.append("|--------------|--------------|------|")
for range_name, count in percent_error_ranges:
    pct = count / len(y_test) * 100
    md_lines.append(f"| {range_name} | {count:,} | %{pct:.2f} |")
md_lines.append("\n")

md_lines.append("### ğŸ¯ Prediction Confidence Intervals (95% CI)\n")
md_lines.append("```")
md_lines.append(f"Genel: Â±{ci_95:.2f} gÃ¼n")
for cat in sorted(y_test['jail_category'].unique()):
    mask = y_test['jail_category'] == cat
    mae_cat = y_test.loc[mask, 'abs_error'].mean()
    ci_cat = 1.96 * mae_cat
    md_lines.append(f"{cat}: Â±{ci_cat:.2f} gÃ¼n")
md_lines.append("```\n")

md_lines.append("### ğŸ† En Ä°yi 5 Tahmin (En DÃ¼ÅŸÃ¼k Mutlak Hata)\n")
md_lines.append("| GerÃ§ek (gÃ¼n) | Tahmin (gÃ¼n) | Hata | Kategori |")
md_lines.append("|--------------|--------------|------|----------|")
for _, row in best_predictions.head(5).iterrows():
    md_lines.append(f"| {row['jail']:.0f} | {row['y_pred']:.0f} | {row['error']:.2f} | {row['jail_category']} |")
md_lines.append("\n")

md_lines.append("### âŒ En KÃ¶tÃ¼ 5 Tahmin (En YÃ¼ksek Mutlak Hata)\n")
md_lines.append("| GerÃ§ek (gÃ¼n) | Tahmin (gÃ¼n) | Hata | Kategori |")
md_lines.append("|--------------|--------------|------|----------|")
for _, row in worst_predictions.head(5).iterrows():
    md_lines.append(f"| {row['jail']:.0f} | {row['y_pred']:.0f} | {row['error']:.2f} | {row['jail_category']} |")
md_lines.append("\n")

md_lines.append("### ğŸ“ Kaydedilen Dosyalar\n")
md_lines.append("```")
md_lines.append("outputs/performance/")
md_lines.append("  â”œâ”€â”€ kategori_bazli_performans.png")
md_lines.append("  â”œâ”€â”€ hata_dagilim_analizi.png")
md_lines.append("  â”œâ”€â”€ kategori_metrikleri.csv")
md_lines.append("  â”œâ”€â”€ en_iyi_tahminler.csv")
md_lines.append("  â””â”€â”€ en_kotu_tahminler.csv")
md_lines.append("```\n")

md_lines.append("### âœ… Ã–nemli Bulgular (Tez Ä°Ã§in)\n")
md_lines.append(f"1. **Kategori PerformansÄ±:** Model, 'Hafif' cezalarda en iyi performansÄ± gÃ¶steriyor (MAE: {category_df[category_df['Kategori'].str.contains('Hafif')]['MAE'].values[0]:.2f} gÃ¼n). 'AÄŸÄ±r' cezalarda performans dÃ¼ÅŸÃ¼yor ancak bu kategori veri setinin sadece %{(category_df[category_df['Kategori'].str.contains('AÄŸÄ±r')]['N'].values[0]/len(y_test)*100):.1f}'Ã¼nÃ¼ oluÅŸturuyor.\n")
md_lines.append(f"2. **Tahmin GÃ¼venilirliÄŸi:** Tahminlerin %{percent_error_ranges[2][1]/len(y_test)*100:.1f}'i Â±50% hata aralÄ±ÄŸÄ±nda, %{percent_error_ranges[3][1]/len(y_test)*100:.1f}'i Â±100% hata aralÄ±ÄŸÄ±nda. Bu, Ã§oÄŸu tahmin iÃ§in makul bir doÄŸruluk seviyesi.\n")
md_lines.append(f"3. **GÃ¼ven AralÄ±klarÄ±:** 95% gÃ¼ven aralÄ±ÄŸÄ± Â±{ci_95:.0f} gÃ¼n. Pratik kullanÄ±mda, model tahminleri bu aralÄ±k iÃ§inde deÄŸerlendirilmelidir.\n")
md_lines.append(f"4. **Outlier Etkisi:** En kÃ¶tÃ¼ tahminlerde bÃ¼yÃ¼k hatalar (10,000+ gÃ¼n) gÃ¶rÃ¼lÃ¼yor. Bu, Ã§ok uzun cezalarÄ±n (10+ yÄ±l) veri setinde nadir olmasÄ± nedeniyle beklenen bir durumdur.\n")

md_lines.append("---\n")

# Dosyaya ekle
with open(SONUCLAR_PATH, 'a', encoding='utf-8') as f:
    f.write('\n'.join(md_lines))

print(f"âœ… SONUCLAR.md gÃ¼ncellendi: {SONUCLAR_PATH}")

print("\n" + "=" * 80)
print("âœ… ADIM 9 TAMAMLANDI!")
print("=" * 80)
print(f"\nğŸ“Š Performans Ã–zeti:")
print(f"  â€¢ En iyi kategori: Hafif cezalar (MAE: {category_df[category_df['Kategori'].str.contains('Hafif')]['MAE'].values[0]:.2f} gÃ¼n)")
print(f"  â€¢ Genel 95% CI: Â±{ci_95:.0f} gÃ¼n")
print(f"  â€¢ Tahminlerin %{percent_error_ranges[2][1]/len(y_test)*100:.1f}'i Â±50% hata aralÄ±ÄŸÄ±nda")
print(f"\nğŸ“Œ Sonraki adÄ±m: SHAP Analizi (Model Explainability)")
