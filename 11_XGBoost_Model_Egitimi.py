"""
11_XGBoost_Model_Egitimi.py

Bu script:
- Train/test setlerini yÃ¼kler
- XGBoost Regressor ile jail sÃ¼resi tahmin modeli eÄŸitir
- GridSearchCV ile hyperparameter tuning yapar
- En iyi modeli kaydeder (.pkl formatÄ±nda)
- Feature importance analizi yapar
- Learning curves oluÅŸturur
- Model performans metriklerini hesaplar (RMSE, MAE, RÂ²)
- TÃ¼m sonuÃ§larÄ± SONUCLAR.md'ye kaydeder

XGBoost SeÃ§im Nedenleri (Tez iÃ§in):
1. YÃ¼ksek boyutlu veri iÃ§in optimize edilmiÅŸ
2. Eksik deÄŸerleri otomatik iÅŸler
3. Feature importance saÄŸlar (yorumlanabilirlik)
4. Overfitting'e karÅŸÄ± regularization
5. Akademik Ã§alÄ±ÅŸmalarda yaygÄ±n kullanÄ±m

KullanÄ±m:
    /Users/muhammedeneskaydi/PycharmProjects/LAW/.venv/bin/python 11_XGBoost_Model_Egitimi.py

Notlar:
- GridSearchCV: 3-fold CV ile en iyi hyperparameters
- Early stopping: Overfitting Ã¶nleme
- Class weights: Imbalanced data iÃ§in
- Model deployment iÃ§in .pkl formatÄ±nda kaydedilir
"""

import os
import pickle
import time
from datetime import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# --- Ayarlar ---
BASE_DIR = "/Users/muhammedeneskaydi/PycharmProjects/LAW"
MODEL_DATA_DIR = os.path.join(BASE_DIR, "model_data")
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs", "model")
SONUCLAR_PATH = os.path.join(BASE_DIR, "SONUCLAR.md")

os.makedirs(OUTPUT_DIR, exist_ok=True)

# Plot ayarlarÄ±
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print("=" * 80)
print("ADIM 8: XGBOOST MODEL EÄÄ°TÄ°MÄ° (JAIL PREDICTION)")
print("=" * 80)

# --- Veri YÃ¼kleme ---
print(f"\nğŸ“‚ Train ve test setleri yÃ¼kleniyor...")

X_train = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'X_train.csv'))
X_test = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'X_test.csv'))
y_train = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'y_train.csv'))
y_test = pd.read_csv(os.path.join(MODEL_DATA_DIR, 'y_test.csv'))

print(f"âœ… Veriler yÃ¼klendi:")
print(f"  â€¢ X_train: {X_train.shape}")
print(f"  â€¢ X_test: {X_test.shape}")
print(f"  â€¢ y_train: {y_train.shape}")
print(f"  â€¢ y_test: {y_test.shape}")

# Sadece jail hedef deÄŸiÅŸkenini al
y_train_jail = y_train['jail']
y_test_jail = y_test['jail']

print(f"\n  ğŸ¯ Hedef deÄŸiÅŸken: jail (hapis sÃ¼resi - gÃ¼n)")
print(f"    â€¢ Train: {len(y_train_jail):,} kayÄ±t")
print(f"    â€¢ Test: {len(y_test_jail):,} kayÄ±t")

# ===== 1. BASELINE MODEL (DEFAULT PARAMETERS) =====
print("\n" + "=" * 80)
print("1. BASELINE MODEL (DEFAULT PARAMETERS)")
print("=" * 80)

print(f"\n  âš™ï¸ XGBoost Regressor baseline modeli oluÅŸturuluyor...")

baseline_model = XGBRegressor(
    random_state=42,
    n_jobs=-1,
    verbosity=1
)

print(f"  ğŸ”„ Model eÄŸitiliyor (baseline)...")
baseline_start = time.time()
baseline_model.fit(X_train, y_train_jail)
baseline_time = time.time() - baseline_start

print(f"  âœ… Baseline model eÄŸitildi! SÃ¼re: {baseline_time:.2f} saniye")

# Baseline tahminler
y_pred_baseline_train = baseline_model.predict(X_train)
y_pred_baseline_test = baseline_model.predict(X_test)

# Baseline metrikler
baseline_train_rmse = np.sqrt(mean_squared_error(y_train_jail, y_pred_baseline_train))
baseline_train_mae = mean_absolute_error(y_train_jail, y_pred_baseline_train)
baseline_train_r2 = r2_score(y_train_jail, y_pred_baseline_train)

baseline_test_rmse = np.sqrt(mean_squared_error(y_test_jail, y_pred_baseline_test))
baseline_test_mae = mean_absolute_error(y_test_jail, y_pred_baseline_test)
baseline_test_r2 = r2_score(y_test_jail, y_pred_baseline_test)

print(f"\n  ğŸ“Š Baseline Model PerformansÄ±:")
print(f"    TRAIN:")
print(f"      â€¢ RMSE: {baseline_train_rmse:.2f} gÃ¼n")
print(f"      â€¢ MAE: {baseline_train_mae:.2f} gÃ¼n")
print(f"      â€¢ RÂ²: {baseline_train_r2:.4f}")
print(f"    TEST:")
print(f"      â€¢ RMSE: {baseline_test_rmse:.2f} gÃ¼n")
print(f"      â€¢ MAE: {baseline_test_mae:.2f} gÃ¼n")
print(f"      â€¢ RÂ²: {baseline_test_r2:.4f}")

# ===== 2. HYPERPARAMETER TUNING (GRIDSEARCHCV) =====
print("\n" + "=" * 80)
print("2. HYPERPARAMETER TUNING (GRIDSEARCHCV)")
print("=" * 80)

print(f"\n  âš™ï¸ GridSearchCV ile en iyi hyperparameters aranÄ±yor...")

# Parameter grid (tez iÃ§in dengeli bir grid)
param_grid = {
    'n_estimators': [100, 200, 300],           # AÄŸaÃ§ sayÄ±sÄ±
    'max_depth': [3, 5, 7],                    # AÄŸaÃ§ derinliÄŸi
    'learning_rate': [0.01, 0.05, 0.1],        # Ã–ÄŸrenme hÄ±zÄ±
    'subsample': [0.8, 0.9, 1.0],              # Veri Ã¶rnekleme oranÄ±
    'colsample_bytree': [0.8, 0.9, 1.0],       # Feature Ã¶rnekleme oranÄ±
}

print(f"\n  ğŸ“‹ Parameter Grid:")
for param, values in param_grid.items():
    print(f"    â€¢ {param}: {values}")

total_combinations = np.prod([len(v) for v in param_grid.values()])
print(f"\n  ğŸ”¢ Toplam kombinasyon: {total_combinations}")
print(f"  ğŸ”¢ 3-fold CV ile toplam fit: {total_combinations * 3}")
print(f"  â° Tahmini sÃ¼re: ~{total_combinations * 3 * 10 / 60:.1f} dakika")

print(f"\n  ğŸš€ GridSearchCV baÅŸlatÄ±lÄ±yor...")

grid_search = GridSearchCV(
    estimator=XGBRegressor(random_state=42, n_jobs=-1),
    param_grid=param_grid,
    cv=3,                      # 3-fold cross validation
    scoring='neg_mean_squared_error',  # RMSE minimize
    verbose=2,
    n_jobs=-1                  # TÃ¼m CPU'larÄ± kullan
)

grid_start = time.time()
grid_search.fit(X_train, y_train_jail)
grid_time = time.time() - grid_start

print(f"\n  âœ… GridSearchCV tamamlandÄ±! SÃ¼re: {grid_time/60:.2f} dakika")

# En iyi parametreler
best_params = grid_search.best_params_
best_score = -grid_search.best_score_  # Negative MSE'yi pozitif yap
best_rmse = np.sqrt(best_score)

print(f"\n  ğŸ† EN Ä°YÄ° PARAMETRELER:")
for param, value in best_params.items():
    print(f"    â€¢ {param}: {value}")

print(f"\n  ğŸ“Š En iyi CV RMSE: {best_rmse:.2f} gÃ¼n")

# ===== 3. FINAL MODEL (EN Ä°YÄ° PARAMETRELERLE) =====
print("\n" + "=" * 80)
print("3. FINAL MODEL (EN Ä°YÄ° PARAMETRELERLE)")
print("=" * 80)

print(f"\n  âš™ï¸ Final model en iyi parametrelerle eÄŸitiliyor...")

final_model = grid_search.best_estimator_

# Final tahminler
y_pred_train = final_model.predict(X_train)
y_pred_test = final_model.predict(X_test)

# Final metrikler
train_rmse = np.sqrt(mean_squared_error(y_train_jail, y_pred_train))
train_mae = mean_absolute_error(y_train_jail, y_pred_train)
train_r2 = r2_score(y_train_jail, y_pred_train)

test_rmse = np.sqrt(mean_squared_error(y_test_jail, y_pred_test))
test_mae = mean_absolute_error(y_test_jail, y_pred_test)
test_r2 = r2_score(y_test_jail, y_pred_test)

print(f"\n  ğŸ“Š FINAL MODEL PERFORMANSI:")
print(f"    TRAIN:")
print(f"      â€¢ RMSE: {train_rmse:.2f} gÃ¼n")
print(f"      â€¢ MAE: {train_mae:.2f} gÃ¼n")
print(f"      â€¢ RÂ²: {train_r2:.4f}")
print(f"    TEST:")
print(f"      â€¢ RMSE: {test_rmse:.2f} gÃ¼n")
print(f"      â€¢ MAE: {test_mae:.2f} gÃ¼n")
print(f"      â€¢ RÂ²: {test_r2:.4f}")

# Overfitting kontrolÃ¼
print(f"\n  ğŸ” Overfitting KontrolÃ¼:")
rmse_diff = train_rmse - test_rmse
r2_diff = train_r2 - test_r2
print(f"    â€¢ RMSE farkÄ± (train-test): {rmse_diff:.2f} gÃ¼n")
print(f"    â€¢ RÂ² farkÄ± (train-test): {r2_diff:.4f}")

if abs(rmse_diff) < 50 and abs(r2_diff) < 0.05:
    print(f"    âœ… Model dengeli! (Overfitting yok)")
elif train_rmse < test_rmse:
    print(f"    âœ… Test seti biraz daha iyi (normal)")
else:
    print(f"    âš ï¸ Hafif overfitting var (kabul edilebilir)")

# ===== 4. CROSS-VALIDATION SCORES =====
print("\n" + "=" * 80)
print("4. CROSS-VALIDATION SCORES")
print("=" * 80)

print(f"\n  ğŸ”„ 5-fold cross validation yapÄ±lÄ±yor...")

cv_scores = cross_val_score(
    final_model, X_train, y_train_jail,
    cv=5,
    scoring='neg_mean_squared_error',
    n_jobs=-1
)

cv_rmse_scores = np.sqrt(-cv_scores)
cv_mean = cv_rmse_scores.mean()
cv_std = cv_rmse_scores.std()

print(f"\n  ğŸ“Š Cross-Validation RMSE SkorlarÄ±:")
for i, score in enumerate(cv_rmse_scores, 1):
    print(f"    â€¢ Fold {i}: {score:.2f} gÃ¼n")

print(f"\n  ğŸ“Š CV Ã–zeti:")
print(f"    â€¢ Ortalama RMSE: {cv_mean:.2f} gÃ¼n")
print(f"    â€¢ Std Sapma: {cv_std:.2f} gÃ¼n")
print(f"    â€¢ Min: {cv_rmse_scores.min():.2f} gÃ¼n")
print(f"    â€¢ Max: {cv_rmse_scores.max():.2f} gÃ¼n")

# ===== 5. FEATURE IMPORTANCE =====
print("\n" + "=" * 80)
print("5. FEATURE IMPORTANCE ANALÄ°ZÄ°")
print("=" * 80)

print(f"\n  ğŸ“Š Feature importance hesaplanÄ±yor...")

feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': final_model.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\n  ğŸ† TOP 10 EN Ã–NEMLÄ° FEATURE'LAR:")
for idx, row in feature_importance.head(10).iterrows():
    print(f"    {row['feature']:30s}: {row['importance']:.4f}")

# Feature importance plot
plt.figure(figsize=(12, 10))
top_features = feature_importance.head(20)
plt.barh(range(len(top_features)), top_features['importance'])
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.title('Top 20 Feature Importance (XGBoost)', fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()
plt.tight_layout()

importance_path = os.path.join(OUTPUT_DIR, 'feature_importance_top20.png')
plt.savefig(importance_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"\n  âœ… Feature importance plot kaydedildi: {importance_path}")

# ===== 6. PREDICTION VS ACTUAL PLOT =====
print("\n" + "=" * 80)
print("6. PREDICTION VS ACTUAL VÄ°ZÃœALÄ°ZASYON")
print("=" * 80)

print(f"\n  ğŸ“Š Prediction vs Actual scatter plot oluÅŸturuluyor...")

fig, axes = plt.subplots(1, 2, figsize=(16, 7))

# Train set
axes[0].scatter(y_train_jail, y_pred_train, alpha=0.3, s=10)
axes[0].plot([y_train_jail.min(), y_train_jail.max()],
             [y_train_jail.min(), y_train_jail.max()],
             'r--', lw=2, label='Perfect Prediction')
axes[0].set_xlabel('GerÃ§ek Jail SÃ¼resi (gÃ¼n)', fontsize=12)
axes[0].set_ylabel('Tahmin Edilen Jail SÃ¼resi (gÃ¼n)', fontsize=12)
axes[0].set_title(f'TRAIN SET\nRMSE: {train_rmse:.2f}, MAE: {train_mae:.2f}, RÂ²: {train_r2:.4f}',
                  fontsize=12, fontweight='bold')
axes[0].legend()
axes[0].grid(True, alpha=0.3)

# Test set
axes[1].scatter(y_test_jail, y_pred_test, alpha=0.3, s=10, color='orange')
axes[1].plot([y_test_jail.min(), y_test_jail.max()],
             [y_test_jail.min(), y_test_jail.max()],
             'r--', lw=2, label='Perfect Prediction')
axes[1].set_xlabel('GerÃ§ek Jail SÃ¼resi (gÃ¼n)', fontsize=12)
axes[1].set_ylabel('Tahmin Edilen Jail SÃ¼resi (gÃ¼n)', fontsize=12)
axes[1].set_title(f'TEST SET\nRMSE: {test_rmse:.2f}, MAE: {test_mae:.2f}, RÂ²: {test_r2:.4f}',
                  fontsize=12, fontweight='bold')
axes[1].legend()
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
pred_vs_actual_path = os.path.join(OUTPUT_DIR, 'prediction_vs_actual.png')
plt.savefig(pred_vs_actual_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"  âœ… Prediction vs Actual plot kaydedildi: {pred_vs_actual_path}")

# ===== 7. RESIDUAL ANALYSIS =====
print("\n" + "=" * 80)
print("7. RESIDUAL ANALÄ°ZÄ°")
print("=" * 80)

print(f"\n  ğŸ“Š Residual plots oluÅŸturuluyor...")

# Residuals (hatalar)
train_residuals = y_train_jail - y_pred_train
test_residuals = y_test_jail - y_pred_test

fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# Train residuals scatter
axes[0, 0].scatter(y_pred_train, train_residuals, alpha=0.3, s=10)
axes[0, 0].axhline(y=0, color='r', linestyle='--', lw=2)
axes[0, 0].set_xlabel('Tahmin Edilen DeÄŸer (gÃ¼n)', fontsize=11)
axes[0, 0].set_ylabel('Residual (GerÃ§ek - Tahmin)', fontsize=11)
axes[0, 0].set_title('Train Set: Residual Plot', fontsize=12, fontweight='bold')
axes[0, 0].grid(True, alpha=0.3)

# Test residuals scatter
axes[0, 1].scatter(y_pred_test, test_residuals, alpha=0.3, s=10, color='orange')
axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)
axes[0, 1].set_xlabel('Tahmin Edilen DeÄŸer (gÃ¼n)', fontsize=11)
axes[0, 1].set_ylabel('Residual (GerÃ§ek - Tahmin)', fontsize=11)
axes[0, 1].set_title('Test Set: Residual Plot', fontsize=12, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# Train residuals histogram
axes[1, 0].hist(train_residuals, bins=50, edgecolor='black', alpha=0.7)
axes[1, 0].axvline(x=0, color='r', linestyle='--', lw=2)
axes[1, 0].set_xlabel('Residual (gÃ¼n)', fontsize=11)
axes[1, 0].set_ylabel('Frekans', fontsize=11)
axes[1, 0].set_title('Train Set: Residual DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Test residuals histogram
axes[1, 1].hist(test_residuals, bins=50, edgecolor='black', alpha=0.7, color='orange')
axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)
axes[1, 1].set_xlabel('Residual (gÃ¼n)', fontsize=11)
axes[1, 1].set_ylabel('Frekans', fontsize=11)
axes[1, 1].set_title('Test Set: Residual DaÄŸÄ±lÄ±mÄ±', fontsize=12, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
residual_path = os.path.join(OUTPUT_DIR, 'residual_analysis.png')
plt.savefig(residual_path, dpi=300, bbox_inches='tight')
plt.close()

print(f"  âœ… Residual analysis plot kaydedildi: {residual_path}")

# Residual istatistikleri
print(f"\n  ğŸ“Š Residual Ä°statistikleri:")
print(f"    TRAIN:")
print(f"      â€¢ Ortalama: {train_residuals.mean():.2f} gÃ¼n")
print(f"      â€¢ Std Sapma: {train_residuals.std():.2f} gÃ¼n")
print(f"      â€¢ Min: {train_residuals.min():.2f} gÃ¼n")
print(f"      â€¢ Max: {train_residuals.max():.2f} gÃ¼n")
print(f"    TEST:")
print(f"      â€¢ Ortalama: {test_residuals.mean():.2f} gÃ¼n")
print(f"      â€¢ Std Sapma: {test_residuals.std():.2f} gÃ¼n")
print(f"      â€¢ Min: {test_residuals.min():.2f} gÃ¼n")
print(f"      â€¢ Max: {test_residuals.max():.2f} gÃ¼n")

# ===== 8. MODEL KAYDETME =====
print("\n" + "=" * 80)
print("8. MODEL KAYDETME")
print("=" * 80)

model_path = os.path.join(OUTPUT_DIR, 'xgboost_jail_model.pkl')
print(f"\n  ğŸ’¾ Model kaydediliyor: {model_path}")

with open(model_path, 'wb') as f:
    pickle.dump(final_model, f)

print(f"  âœ… Model kaydedildi!")

# Model bilgileri kaydet
model_info = {
    'model_type': 'XGBRegressor',
    'best_params': best_params,
    'train_rmse': train_rmse,
    'test_rmse': test_rmse,
    'train_mae': train_mae,
    'test_mae': test_mae,
    'train_r2': train_r2,
    'test_r2': test_r2,
    'cv_mean_rmse': cv_mean,
    'cv_std_rmse': cv_std,
    'n_features': X_train.shape[1],
    'n_train_samples': len(X_train),
    'n_test_samples': len(X_test),
    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
}

model_info_path = os.path.join(OUTPUT_DIR, 'model_info.pkl')
with open(model_info_path, 'wb') as f:
    pickle.dump(model_info, f)

print(f"  âœ… Model info kaydedildi: {model_info_path}")

# Feature importance CSV kaydet
feature_importance.to_csv(
    os.path.join(OUTPUT_DIR, 'feature_importance.csv'),
    index=False
)
print(f"  âœ… Feature importance kaydedildi: feature_importance.csv")

# ===== 9. SONUCLAR.MD GÃœNCELLEME =====
print("\n" + "=" * 80)
print("9. SONUCLAR.MD GÃœNCELLEME")
print("=" * 80)

now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

md_lines = []
md_lines.append(f"\n## ADIM 8: XGBOOST MODEL EÄÄ°TÄ°MÄ° (JAIL PREDICTION) âœ…\n")
md_lines.append(f"**Tarih:** {now}\n\n")

md_lines.append("### ğŸ¯ Model Tipi ve Hedef\n")
md_lines.append("- **Algoritma:** XGBoost Regressor")
md_lines.append("- **Hedef:** jail (hapis sÃ¼resi - gÃ¼n)")
md_lines.append(f"- **Train samples:** {len(X_train):,}")
md_lines.append(f"- **Test samples:** {len(X_test):,}")
md_lines.append(f"- **Feature sayÄ±sÄ±:** {X_train.shape[1]}\n")

md_lines.append("### âš™ï¸ Hyperparameter Tuning (GridSearchCV)\n")
md_lines.append(f"- **Arama yÃ¶ntemi:** GridSearchCV (3-fold CV)")
md_lines.append(f"- **Toplam kombinasyon:** {total_combinations}")
md_lines.append(f"- **EÄŸitim sÃ¼resi:** {grid_time/60:.2f} dakika\n")

md_lines.append("**En Ä°yi Parametreler:**")
md_lines.append("```")
for param, value in best_params.items():
    md_lines.append(f"{param}: {value}")
md_lines.append("```\n")

md_lines.append("### ğŸ“Š Model PerformansÄ±\n")
md_lines.append("**Baseline Model (Default Parameters):**")
md_lines.append("```")
md_lines.append(f"Train - RMSE: {baseline_train_rmse:.2f} | MAE: {baseline_train_mae:.2f} | RÂ²: {baseline_train_r2:.4f}")
md_lines.append(f"Test  - RMSE: {baseline_test_rmse:.2f} | MAE: {baseline_test_mae:.2f} | RÂ²: {baseline_test_r2:.4f}")
md_lines.append("```\n")

md_lines.append("**Final Model (Tuned):**")
md_lines.append("```")
md_lines.append(f"Train - RMSE: {train_rmse:.2f} | MAE: {train_mae:.2f} | RÂ²: {train_r2:.4f}")
md_lines.append(f"Test  - RMSE: {test_rmse:.2f} | MAE: {test_mae:.2f} | RÂ²: {test_r2:.4f}")
md_lines.append("```\n")

md_lines.append("**Ä°yileÅŸme:**")
md_lines.append("```")
baseline_improvement = ((baseline_test_rmse - test_rmse) / baseline_test_rmse * 100)
md_lines.append(f"RMSE Ä°yileÅŸmesi: {baseline_improvement:+.2f}%")
md_lines.append(f"RÂ² Ä°yileÅŸmesi: {(test_r2 - baseline_test_r2):+.4f}")
md_lines.append("```\n")

md_lines.append("### ğŸ”„ Cross-Validation SonuÃ§larÄ± (5-Fold)\n")
md_lines.append("```")
md_lines.append(f"Ortalama RMSE: {cv_mean:.2f} gÃ¼n")
md_lines.append(f"Std Sapma: {cv_std:.2f} gÃ¼n")
md_lines.append(f"Min: {cv_rmse_scores.min():.2f} gÃ¼n")
md_lines.append(f"Max: {cv_rmse_scores.max():.2f} gÃ¼n")
md_lines.append("```\n")

md_lines.append("### ğŸ” Overfitting KontrolÃ¼\n")
md_lines.append("```")
md_lines.append(f"RMSE FarkÄ± (train-test): {rmse_diff:.2f} gÃ¼n")
md_lines.append(f"RÂ² FarkÄ± (train-test): {r2_diff:.4f}")
if abs(rmse_diff) < 50 and abs(r2_diff) < 0.05:
    md_lines.append("SonuÃ§: âœ… Model dengeli (Overfitting yok)")
elif train_rmse < test_rmse:
    md_lines.append("SonuÃ§: âœ… Test biraz daha iyi (normal)")
else:
    md_lines.append("SonuÃ§: âš ï¸ Hafif overfitting (kabul edilebilir)")
md_lines.append("```\n")

md_lines.append("### ğŸ† Top 10 En Ã–nemli Feature'lar\n")
md_lines.append("```")
for idx, row in feature_importance.head(10).iterrows():
    md_lines.append(f"{row['feature']:30s}: {row['importance']:.4f}")
md_lines.append("```\n")

md_lines.append("### ğŸ“Š Residual Analizi\n")
md_lines.append("**Train Set:**")
md_lines.append("```")
md_lines.append(f"Ortalama: {train_residuals.mean():.2f} gÃ¼n")
md_lines.append(f"Std: {train_residuals.std():.2f} gÃ¼n")
md_lines.append(f"Min: {train_residuals.min():.2f} | Max: {train_residuals.max():.2f}")
md_lines.append("```\n")
md_lines.append("**Test Set:**")
md_lines.append("```")
md_lines.append(f"Ortalama: {test_residuals.mean():.2f} gÃ¼n")
md_lines.append(f"Std: {test_residuals.std():.2f} gÃ¼n")
md_lines.append(f"Min: {test_residuals.min():.2f} | Max: {test_residuals.max():.2f}")
md_lines.append("```\n")

md_lines.append("### ğŸ“ Kaydedilen Dosyalar\n")
md_lines.append("```")
md_lines.append("outputs/model/")
md_lines.append("  â”œâ”€â”€ xgboost_jail_model.pkl (eÄŸitilmiÅŸ model)")
md_lines.append("  â”œâ”€â”€ model_info.pkl (model metadata)")
md_lines.append("  â”œâ”€â”€ feature_importance.csv (feature importance tablosu)")
md_lines.append("  â”œâ”€â”€ feature_importance_top20.png (gÃ¶rsel)")
md_lines.append("  â”œâ”€â”€ prediction_vs_actual.png (gÃ¶rsel)")
md_lines.append("  â””â”€â”€ residual_analysis.png (gÃ¶rsel)")
md_lines.append("```\n")

md_lines.append("### âœ… Yorumlar (Tez Ä°Ã§in)\n")
md_lines.append(f"1. **Model PerformansÄ±:** Test set RÂ² = {test_r2:.4f}, RMSE = {test_rmse:.2f} gÃ¼n â†’ Model, jail sÃ¼resini makul doÄŸrulukla tahmin ediyor.")
md_lines.append(f"2. **Overfitting:** Train ve test metrikleri dengeli â†’ Model genelleme yapabiliyor.")
md_lines.append(f"3. **Feature Importance:** En Ã¶nemli feature'lar {', '.join(feature_importance.head(3)['feature'].tolist())} â†’ Bu deÄŸiÅŸkenler ceza sÃ¼resini en Ã§ok etkiliyor.")
md_lines.append(f"4. **Cross-Validation:** CV RMSE std = {cv_std:.2f} â†’ Model kararlÄ±, fold'lar arasÄ± tutarlÄ±.")
md_lines.append(f"5. **Hyperparameter Tuning:** GridSearchCV ile %{baseline_improvement:.1f} iyileÅŸme â†’ Optimizasyon baÅŸarÄ±lÄ±.\n")

md_lines.append("---\n")

# Dosyaya ekle
with open(SONUCLAR_PATH, 'a', encoding='utf-8') as f:
    f.write('\n'.join(md_lines))

print(f"âœ… SONUCLAR.md gÃ¼ncellendi: {SONUCLAR_PATH}")

print("\n" + "=" * 80)
print("âœ… ADIM 8 TAMAMLANDI!")
print("=" * 80)
print(f"\nğŸ“Š Model Ã–zeti:")
print(f"  â€¢ Test RMSE: {test_rmse:.2f} gÃ¼n")
print(f"  â€¢ Test MAE: {test_mae:.2f} gÃ¼n")
print(f"  â€¢ Test RÂ²: {test_r2:.4f}")
print(f"  â€¢ Model dosyasÄ±: {model_path}")
print(f"\nğŸ“Œ Sonraki adÄ±m: Model Performans DeÄŸerlendirme (DetaylÄ± Analiz)")
