
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from catboost import CatBoostRegressor
from pathlib import Path
import joblib
import warnings

# Ayarlar
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("colorblind")

VERI_YOLU = "/Users/muhammedeneskaydi/PycharmProjects/LAW/wcld.csv"
MODEL_DIR = Path("../model_data_v2_interactions")
OUTPUT_DIR = Path("../outputs/bias_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def load_models_and_features():
    if not MODEL_DIR.exists():
        print("âŒ Model klasÃ¶rÃ¼ bulunamadÄ±! Ã–nce modelleri eÄŸitin.")
        return None, None, None, None, None
        
    router = joblib.load(MODEL_DIR / "cat_features_v2.pkl") # Placeholder check
    features = joblib.load(MODEL_DIR / "features_v2.pkl")
    cat_features = joblib.load(MODEL_DIR / "cat_features_v2.pkl")
    
    # Modelleri yÃ¼klemek yerine tahminleri sÄ±fÄ±rdan yapmak daha temiz olabilir
    # Ama burada script iÃ§inde tekrar predict logic kurmak uzun.
    # KolaylÄ±k olsun diye: Modeli yÃ¼kleyip tahmin alacaÄŸÄ±z.
    # Ancak pipeline karmaÅŸÄ±k (Router + 2 Model).
    # Basitlik adÄ±na: 'step_16' scripti zaten tahminleri CSV'ye dÃ¶kseydi iyiydi.
    # Neyse, burada basitÃ§e Mainstream (Model Low) Ã¼zerinden bias bakalÄ±m.
    # Ã‡oÄŸunluk veri (%92) orada olduÄŸu iÃ§in bias asÄ±l orada aranmalÄ±.
    
    model_low = CatBoostRegressor()
    model_low.load_model(str(MODEL_DIR / "model_low_v2.cbm"))
    
    return model_low, features, cat_features

def analyze_bias():
    print(f"ğŸ“‚ Veri yÃ¼kleniyor: {VERI_YOLU}")
    try:
        df = pd.read_csv(VERI_YOLU, low_memory=False)
    except FileNotFoundError:
        print("âŒ HATA: Dosya bulunamadÄ±!")
        return

    # Veri HazÄ±rlÄ±ÄŸÄ±
    if 'jail' not in df.columns: return
    df = df[df['jail'] > 300].copy()
    ust_sinir = df['jail'].quantile(0.995)
    df = df[df['jail'] <= ust_sinir].copy()
    
    # 3000 AltÄ± Veri (Mainstream Bias Analizi)
    df_main = df[df['jail'] <= 3000].copy()
    print(f"âœ… Analiz KapsamÄ±: 300-3000 gÃ¼n arasÄ± {len(df_main)} dava (Verinin %92'si)")
    
    # Interaction Features Ekle (Model bunlarÄ± bekliyor)
    if 'highest_severity' in df_main.columns and 'violent_crime' in df_main.columns:
        df_main['severity_x_violent'] = df_main['highest_severity'] * df_main['violent_crime']
    if 'age_judge' in df_main.columns and 'age_offense' in df_main.columns:
        df_main['age_judge'] = df_main['age_judge'].fillna(df_main['age_judge'].mean())
        df_main['age_offense'] = df_main['age_offense'].fillna(df_main['age_offense'].mean())
        df_main['age_gap'] = df_main['age_judge'] - df_main['age_offense']
    if 'is_recid_new' in df_main.columns and 'violent_crime' in df_main.columns:
        df_main['violent_recid'] = df_main['is_recid_new'] * df_main['violent_crime']
        
    model, features, cat_features = load_models_and_features()
    if model is None: return

    # Kategorik HazÄ±rlÄ±k
    X = df_main[features].copy()
    for col in cat_features:
        if col in X.columns:
            X[col] = X[col].fillna("Unknown").astype(str)
            
    # SayÄ±sal HazÄ±rlÄ±k
    for col in X.columns:
        if col not in cat_features:
             X[col] = X[col].fillna(X[col].mean())

    print("â³ Tahminler alÄ±nÄ±yor...")
    preds_log = model.predict(X)
    df_main['predicted_jail'] = np.expm1(preds_log)
    df_main['error'] = df_main['predicted_jail'] - df_main['jail']
    df_main['abs_error'] = df_main['error'].abs()
    
    # --- 1. IRK ANALÄ°ZÄ° (RACE BIAS) ---
    print("\nğŸŒ IRK ANALÄ°ZÄ° (Race Bias):")
    race_stats = df_main.groupby('race').agg({
        'jail': 'mean',
        'predicted_jail': 'mean',
        'abs_error': 'mean',
        'highest_severity': 'mean' # SuÃ§ aÄŸÄ±rlÄ±ÄŸÄ± kontrolÃ¼ iÃ§in
    }).sort_values(by='jail', ascending=False)
    
    race_stats['count'] = df_main['race'].value_counts()
    race_stats = race_stats[race_stats['count'] > 100] # AzÄ±nlÄ±klarÄ± filtrele
    
    print(f"{'Irk':<15} | {'Adet':<6} | {'GerÃ§ek Ort.':<12} | {'Tahmin Ort.':<12} | {'Fark (Bias)':<12} | {'Hata (MAE)':<10}")
    print("-" * 80)
    for index, row in race_stats.iterrows():
        bias = row['predicted_jail'] - row['jail']
        print(f"{index:<15} | {int(row['count']):<6} | {row['jail']:<12.1f} | {row['predicted_jail']:<12.1f} | {bias:<12.1f} | {row['abs_error']:<10.1f}")

    # Grafik: Race Bias
    plt.figure(figsize=(10, 6))
    sns.barplot(x=race_stats.index, y=race_stats['predicted_jail'] - race_stats['jail'])
    plt.title('Irklara GÃ¶re Model Ã–nyargÄ±sÄ± (Tahmin - GerÃ§ek)')
    plt.ylabel('GÃ¼n FarkÄ± (+ Fazla Ceza, - Az Ceza)')
    plt.axhline(0, color='black', linestyle='--')
    plt.savefig(OUTPUT_DIR / "race_bias.png")
    
    # --- 2. CÄ°NSÄ°YET ANALÄ°ZÄ° (SEX BIAS) ---
    print("\nğŸ‘« CÄ°NSÄ°YET ANALÄ°ZÄ° (Sex Bias):")
    sex_stats = df_main.groupby('sex').agg({
        'jail': 'mean',
        'predicted_jail': 'mean',
        'abs_error': 'mean'
    })
    print(sex_stats)
    
    # --- 3. KOÅULLU BIAS (Conditional Bias - Severity KontrollÃ¼) ---
    # "Siyahiler daha Ã§ok ceza alÄ±yor Ã§Ã¼nkÃ¼ daha aÄŸÄ±r suÃ§ iÅŸliyorlar" tezini test edelim.
    # Åiddet Skoru (Severity) eÅŸitlendiÄŸinde durum ne?
    
    print("\nâš–ï¸ KOÅULLU BIAS (AynÄ± SuÃ§ Åiddetinde Irk AyrÄ±mÄ± Var mÄ±?):")
    plt.figure(figsize=(12, 6))
    
    # Ä°simleri DÃ¼zelt (Veride 'African American' ve 'Caucasian' geÃ§iyor)
    race_map = {'African American': 'Black', 'Caucasian': 'White'}
    df_main['race_mapped'] = df_main['race'].map(race_map)
    
    # Sadece Black ve White alalÄ±m
    df_bw = df_main[df_main['race_mapped'].isin(['Black', 'White'])]
    
    sns.lineplot(x='highest_severity', y='predicted_jail', hue='race_mapped', data=df_bw, marker='o')
    plt.title('SuÃ§ Åiddetine GÃ¶re Ceza Tahmini: Siyahi vs Beyaz')
    plt.xlabel('SuÃ§ Åiddeti (Severity)')
    plt.ylabel('Tahmin Edilen Ceza (GÃ¼n)')
    plt.savefig(OUTPUT_DIR / "conditional_bias_race.png")
    
    # SayÄ±sal KarÅŸÄ±laÅŸtÄ±rma (Severity GruplarÄ±nda Fark)
    print("\n   [Severity BazlÄ± Siyahi-Beyaz FarkÄ±]")
    df_bw['sev_bin'] = pd.cut(df_bw['highest_severity'], bins=[0, 3, 6, 9, 20], labels=['DÃ¼ÅŸÃ¼k', 'Orta', 'YÃ¼ksek', 'Ã‡ok Yeksek'])
    
    pivot = df_bw.pivot_table(index='sev_bin', columns='race_mapped', values='predicted_jail', aggfunc='mean')
    pivot['Fark (Black - White)'] = pivot['Black'] - pivot['White']
    print(pivot)
    
    print(f"\nğŸ’¾ TÃ¼m analiz grafikleri kaydedildi: {OUTPUT_DIR}")

if __name__ == "__main__":
    analyze_bias()
