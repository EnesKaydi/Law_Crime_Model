"""
ðŸš€ HIGH SEVERITY MODEL IMPROVEMENT EXPERIMENTS
===============================================

Bu script, SADECE High Severity Model (3000+ gÃ¼n) iÃ§in iyileÅŸtirme denemeleri yapar.
Mainstream Model ve Router Model AYNI KALIR.

Hedef: %33 RÂ² â†’ %50+ RÂ²

Stratejiler:
1. Advanced Feature Engineering (Judge-Crime interactions)
2. Ensemble Modeling (Multiple CatBoost models)
3. Hyperparameter Optimization
4. Alternative Loss Functions (Quantile, Huber)
5. Crime Type Clustering
"""

import pandas as pd
import numpy as np
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import joblib

warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-darkgrid')

# Paths
VERI_YOLU = "/Users/muhammedeneskaydi/PycharmProjects/LAW/wcld.csv"
OUTPUT_DIR = Path("../outputs/high_severity_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
MODEL_DIR = Path("../model_data_v2_interactions")

# Constants
THRESHOLD = 3000
RANDOM_STATE = 42


def load_high_severity_data():
    """Sadece High Severity segmentini yÃ¼kle"""
    print("ðŸ“‚ Veri yÃ¼kleniyor...")
    df = pd.read_csv(VERI_YOLU, low_memory=False)
    
    # Temel filtreleme
    df = df[df['jail'] > 300].copy()
    ust_sinir = df['jail'].quantile(0.995)
    df = df[df['jail'] <= ust_sinir].copy()
    
    # Sadece High Severity
    df_high = df[df['jail'] > THRESHOLD].copy()
    
    print(f"âœ… High Severity veri hazÄ±r: {len(df_high):,} vaka")
    return df_high


def create_advanced_features(df):
    """GeliÅŸmiÅŸ Ã¶zellik mÃ¼hendisliÄŸi - High Severity'ye Ã¶zel"""
    print("\nðŸ”§ GeliÅŸmiÅŸ Ã¶zellikler oluÅŸturuluyor...")
    
    # Mevcut interaction features
    if 'highest_severity' in df.columns and 'violent_crime' in df.columns:
        df['severity_x_violent'] = df['highest_severity'] * df['violent_crime']
    
    if 'age_judge' in df.columns and 'age_offense' in df.columns:
        age_j = df['age_judge'].fillna(df['age_judge'].mean())
        age_o = df['age_offense'].fillna(df['age_offense'].mean())
        df['age_gap'] = age_j - age_o
    
    if 'is_recid_new' in df.columns and 'violent_crime' in df.columns:
        df['violent_recid'] = df['is_recid_new'] * df['violent_crime']
    
    # YENÄ° Ã–ZELLIKLER - High Severity'ye Ã–zel
    
    # 1. Judge Harshness Score (Hakim Sertlik Skoru)
    if 'judge_id' in df.columns:
        judge_avg = df.groupby('judge_id')['jail'].transform('mean')
        df['judge_harshness'] = judge_avg
        
        # Judge consistency (varyans)
        judge_std = df.groupby('judge_id')['jail'].transform('std')
        df['judge_consistency'] = judge_std.fillna(0)
    
    # 2. County Harshness Score (BÃ¶lge Sertlik Skoru)
    if 'county' in df.columns:
        county_avg = df.groupby('county')['jail'].transform('mean')
        df['county_harshness'] = county_avg
    
    # 3. Crime Class Severity (SuÃ§ SÄ±nÄ±fÄ± Åžiddeti)
    if 'wcisclass' in df.columns:
        wcis_avg = df.groupby('wcisclass')['jail'].transform('mean')
        df['wcisclass_severity'] = wcis_avg
    
    # 4. Judge-Crime Type Interaction
    if 'judge_id' in df.columns and 'wcisclass' in df.columns:
        df['judge_crime_combo'] = df['judge_id'].astype(str) + '_' + df['wcisclass'].astype(str)
    
    # 5. Recidivism Severity (SabÄ±ka Åžiddeti)
    if 'is_recid_new' in df.columns and 'highest_severity' in df.columns:
        df['recid_severity'] = df['is_recid_new'] * df['highest_severity']
    
    # 6. Total Prior History Score
    prior_cols = ['prior_felony', 'prior_misdemeanor', 'prior_criminal_traffic']
    available_prior = [c for c in prior_cols if c in df.columns]
    if available_prior:
        df['total_prior_score'] = df[available_prior].fillna(0).sum(axis=1)
    
    # 7. Violent Crime x Prior History
    if 'violent_crime' in df.columns and 'total_prior_score' in df.columns:
        df['violent_x_prior'] = df['violent_crime'] * df['total_prior_score']
    
    # 8. Age Risk Factor (GenÃ§ + Åžiddet = YÃ¼ksek Risk)
    if 'age_offense' in df.columns and 'violent_crime' in df.columns:
        age_normalized = (df['age_offense'] - df['age_offense'].mean()) / df['age_offense'].std()
        df['age_risk'] = age_normalized * df['violent_crime']
    
    # 9. Year Trend (YÄ±llar iÃ§inde ceza artÄ±ÅŸÄ±/azalÄ±ÅŸÄ±)
    if 'year' in df.columns:
        df['years_since_2000'] = df['year'] - 2000
        df['year_squared'] = df['years_since_2000'] ** 2
    
    print(f"âœ… {9} yeni Ã¶zellik eklendi!")
    return df


def prepare_features(df):
    """Feature listesini hazÄ±rla"""
    base_features = [
        'highest_severity', 'violent_crime', 'is_recid_new', 'year',
        'wcisclass', 'release', 'max_hist_jail', 'pct_male', 'judge_id',
        'age_judge', 'age_offense', 'pct_black', 'sex', 'race',
        'prior_felony', 'prior_misdemeanor', 'prior_criminal_traffic',
        'avg_hist_jail', 'median_hist_jail', 'min_hist_jail',
        'county', 'case_type', 'zip'
    ]
    base_features.extend([c for c in df.columns if 'prior_charges_severity' in c])
    
    # Mevcut interaction features
    interaction_features = ['severity_x_violent', 'age_gap', 'violent_recid']
    
    # YENÄ° advanced features
    new_features = [
        'judge_harshness', 'judge_consistency', 'county_harshness',
        'wcisclass_severity', 'judge_crime_combo', 'recid_severity',
        'total_prior_score', 'violent_x_prior', 'age_risk',
        'years_since_2000', 'year_squared'
    ]
    
    all_features = base_features + interaction_features + new_features
    available_features = [f for f in all_features if f in df.columns]
    
    # Kategorik belirleme
    cat_features = []
    KNOWN_CAT = ['judge_id', 'county', 'zip', 'case_type', 'race', 'sex', 'wcisclass', 'judge_crime_combo']
    
    X = df[available_features].copy()
    
    for col in X.columns:
        if col in KNOWN_CAT or X[col].dtype == 'object' or X[col].dtype.name == 'category':
            X[col] = X[col].fillna("Unknown").astype(str)
            if col not in cat_features:
                cat_features.append(col)
    
    # SayÄ±sal fillna
    for col in X.columns:
        if col not in cat_features:
            X[col] = X[col].fillna(X[col].mean())
    
    return X, available_features, cat_features


def experiment_1_baseline(X, y, cat_features):
    """Deney 1: Baseline (Mevcut Model)"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 1: BASELINE (Mevcut Hyperparameters)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    model = CatBoostRegressor(
        iterations=1500,
        learning_rate=0.02,
        depth=10,
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE,
        l2_leaf_reg=5
    )
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"âœ… Baseline RÂ²: {r2:.4f}")
    print(f"âœ… Baseline MAE: {mae:.4f}")
    
    return {'model': model, 'r2': r2, 'mae': mae, 'name': 'Baseline'}


def experiment_2_deep_trees(X, y, cat_features):
    """Deney 2: Daha Derin AÄŸaÃ§lar"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 2: DAHA DERÄ°N AÄžAÃ‡LAR (depth=14)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    model = CatBoostRegressor(
        iterations=1500,
        learning_rate=0.02,
        depth=14,  # Daha derin
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE,
        l2_leaf_reg=5
    )
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"âœ… Deep Trees RÂ²: {r2:.4f} (Baseline'den {r2-0.3337:.4f} fark)")
    print(f"âœ… Deep Trees MAE: {mae:.4f}")
    
    return {'model': model, 'r2': r2, 'mae': mae, 'name': 'Deep Trees'}


def experiment_3_more_iterations(X, y, cat_features):
    """Deney 3: Daha Fazla Ä°terasyon"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 3: DAHA FAZLA Ä°TERASYON (3000 iter)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    model = CatBoostRegressor(
        iterations=3000,  # 2x daha fazla
        learning_rate=0.01,  # Daha dÃ¼ÅŸÃ¼k LR
        depth=12,
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE,
        l2_leaf_reg=5
    )
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"âœ… More Iterations RÂ²: {r2:.4f} (Baseline'den {r2-0.3337:.4f} fark)")
    print(f"âœ… More Iterations MAE: {mae:.4f}")
    
    return {'model': model, 'r2': r2, 'mae': mae, 'name': 'More Iterations'}


def experiment_4_ensemble(X, y, cat_features):
    """Deney 4: Ensemble (3 farklÄ± model ortalamasÄ±)"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 4: ENSEMBLE (3 Model OrtalamasÄ±)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    configs = [
        {'iterations': 2000, 'depth': 10, 'learning_rate': 0.02, 'l2_leaf_reg': 3},
        {'iterations': 2000, 'depth': 12, 'learning_rate': 0.015, 'l2_leaf_reg': 5},
        {'iterations': 2000, 'depth': 14, 'learning_rate': 0.01, 'l2_leaf_reg': 7},
    ]
    
    predictions = []
    
    for i, config in enumerate(configs, 1):
        print(f"   Model {i}/3 eÄŸitiliyor...")
        model = CatBoostRegressor(
            **config,
            cat_features=cat_features,
            verbose=0,
            random_seed=RANDOM_STATE + i
        )
        model.fit(X_train, y_train)
        predictions.append(model.predict(X_test))
    
    # Ortalama tahmin
    y_pred_ensemble = np.mean(predictions, axis=0)
    
    r2 = r2_score(y_test, y_pred_ensemble)
    mae = mean_absolute_error(y_test, y_pred_ensemble)
    
    print(f"âœ… Ensemble RÂ²: {r2:.4f} (Baseline'den {r2-0.3337:.4f} fark)")
    print(f"âœ… Ensemble MAE: {mae:.4f}")
    
    return {'model': None, 'r2': r2, 'mae': mae, 'name': 'Ensemble', 'predictions': predictions}


def experiment_5_quantile_loss(X, y, cat_features):
    """Deney 5: Quantile Loss (Median tahmin)"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 5: QUANTILE LOSS (Median Prediction)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    model = CatBoostRegressor(
        iterations=2000,
        learning_rate=0.02,
        depth=12,
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE,
        loss_function='Quantile:alpha=0.5',  # Median
        l2_leaf_reg=5
    )
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"âœ… Quantile Loss RÂ²: {r2:.4f} (Baseline'den {r2-0.3337:.4f} fark)")
    print(f"âœ… Quantile Loss MAE: {mae:.4f}")
    
    return {'model': model, 'r2': r2, 'mae': mae, 'name': 'Quantile Loss'}


def experiment_6_advanced_features_only(X, y, cat_features):
    """Deney 6: Sadece Yeni Advanced Features ile"""
    print("\n" + "="*60)
    print("ðŸ§ª DENEY 6: ADVANCED FEATURES (Yeni Ã–zelliklerle)")
    print("="*60)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)
    
    model = CatBoostRegressor(
        iterations=2500,
        learning_rate=0.015,
        depth=12,
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE,
        l2_leaf_reg=4
    )
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"âœ… Advanced Features RÂ²: {r2:.4f} (Baseline'den {r2-0.3337:.4f} fark)")
    print(f"âœ… Advanced Features MAE: {mae:.4f}")
    
    # Feature importance
    importance = model.get_feature_importance()
    feature_names = X.columns
    top_features = sorted(zip(feature_names, importance), key=lambda x: x[1], reverse=True)[:10]
    
    print(f"\nðŸ“Š Top 10 En Ã–nemli Ã–zellikler:")
    for feat, imp in top_features:
        print(f"   â€¢ {feat}: {imp:.4f}")
    
    return {'model': model, 'r2': r2, 'mae': mae, 'name': 'Advanced Features', 'top_features': top_features}


def compare_results(results):
    """TÃ¼m deneyleri karÅŸÄ±laÅŸtÄ±r"""
    print("\n" + "="*60)
    print("ðŸ“Š SONUÃ‡LARIN KARÅžILAÅžTIRILMASI")
    print("="*60)
    
    # Tablo
    print(f"\n{'Deney':<25} {'RÂ² Score':<15} {'MAE':<15} {'Ä°yileÅŸme':<15}")
    print("-" * 70)
    
    baseline_r2 = 0.3337  # Diagnostic'ten bilinen deÄŸer
    
    for result in results:
        improvement = result['r2'] - baseline_r2
        improvement_pct = (improvement / baseline_r2) * 100
        print(f"{result['name']:<25} {result['r2']:<15.4f} {result['mae']:<15.4f} +{improvement_pct:>6.1f}%")
    
    # En iyi modeli bul
    best_result = max(results, key=lambda x: x['r2'])
    
    print(f"\nðŸ† EN Ä°YÄ° MODEL: {best_result['name']}")
    print(f"   â€¢ RÂ² Score: {best_result['r2']:.4f}")
    print(f"   â€¢ MAE: {best_result['mae']:.4f}")
    print(f"   â€¢ Ä°yileÅŸme: +{((best_result['r2'] - baseline_r2) / baseline_r2) * 100:.1f}%")
    
    # GÃ¶rselleÅŸtirme
    fig, ax = plt.subplots(figsize=(12, 6))
    
    names = [r['name'] for r in results]
    r2_scores = [r['r2'] for r in results]
    
    bars = ax.bar(names, r2_scores, color=['gray' if r['name'] == 'Baseline' else 'steelblue' for r in results])
    
    # En iyi modeli vurgula
    best_idx = names.index(best_result['name'])
    bars[best_idx].set_color('green')
    
    # Hedef Ã§izgisi
    ax.axhline(y=0.50, color='red', linestyle='--', linewidth=2, label='Hedef: 50% RÂ²')
    ax.axhline(y=baseline_r2, color='orange', linestyle='--', linewidth=2, label='Baseline: 33.37% RÂ²')
    
    ax.set_ylabel('RÂ² Score')
    ax.set_title('High Severity Model Ä°yileÅŸtirme Deneyleri')
    ax.legend()
    ax.set_ylim([0, 0.6])
    
    # DeÄŸerleri yazdÄ±r
    for i, (name, r2) in enumerate(zip(names, r2_scores)):
        ax.text(i, r2 + 0.01, f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / '04_improvement_comparison.png', dpi=300, bbox_inches='tight')
    print(f"\nðŸ’¾ GÃ¶rsel kaydedildi: 04_improvement_comparison.png")
    plt.close()
    
    return best_result


def save_best_model(best_result, X, y, cat_features, available_features):
    """En iyi modeli kaydet"""
    print("\n" + "="*60)
    print("ðŸ’¾ EN Ä°YÄ° MODEL KAYDEDÄ°LÄ°YOR")
    print("="*60)
    
    if best_result['name'] == 'Ensemble':
        print("âš ï¸ Ensemble model - 3 ayrÄ± model kaydedilecek")
        # Ensemble iÃ§in 3 modeli yeniden eÄŸit ve kaydet
        # (Åžimdilik atlÄ±yoruz, gerekirse ekleriz)
        return
    
    # TÃ¼m veriyle yeniden eÄŸit
    print("ðŸš€ En iyi model tÃ¼m veriyle yeniden eÄŸitiliyor...")
    
    if best_result['name'] == 'Deep Trees':
        config = {'iterations': 1500, 'learning_rate': 0.02, 'depth': 14, 'l2_leaf_reg': 5}
    elif best_result['name'] == 'More Iterations':
        config = {'iterations': 3000, 'learning_rate': 0.01, 'depth': 12, 'l2_leaf_reg': 5}
    elif best_result['name'] == 'Quantile Loss':
        config = {'iterations': 2000, 'learning_rate': 0.02, 'depth': 12, 'l2_leaf_reg': 5, 'loss_function': 'Quantile:alpha=0.5'}
    elif best_result['name'] == 'Advanced Features':
        config = {'iterations': 2500, 'learning_rate': 0.015, 'depth': 12, 'l2_leaf_reg': 4}
    else:
        config = {'iterations': 1500, 'learning_rate': 0.02, 'depth': 10, 'l2_leaf_reg': 5}
    
    final_model = CatBoostRegressor(
        **config,
        cat_features=cat_features,
        verbose=0,
        random_seed=RANDOM_STATE
    )
    final_model.fit(X, y)
    
    # Kaydet
    final_model.save_model(str(MODEL_DIR / "model_high_v2_improved.cbm"))
    joblib.dump(available_features, MODEL_DIR / "features_v2_improved.pkl")
    
    print(f"âœ… Model kaydedildi: {MODEL_DIR / 'model_high_v2_improved.cbm'}")
    print(f"âœ… Features kaydedildi: {MODEL_DIR / 'features_v2_improved.pkl'}")


def generate_improvement_report(results, best_result):
    """Ä°yileÅŸtirme raporu oluÅŸtur"""
    print("\n" + "="*60)
    print("ðŸ“ Ä°YÄ°LEÅžTÄ°RME RAPORU OLUÅžTURULUYOR")
    print("="*60)
    
    baseline_r2 = 0.3337
    
    report = f"""# High Severity Model Ä°yileÅŸtirme SonuÃ§larÄ±

## Ã–zet

**Hedef:** High Severity Model RÂ² skorunu %33 â†’ %50+ yÃ¼kseltmek

**SonuÃ§:** En iyi model **{best_result['name']}** ile **{best_result['r2']:.2%}** RÂ² elde edildi.

**Ä°yileÅŸme:** +{((best_result['r2'] - baseline_r2) / baseline_r2) * 100:.1f}% (Baseline: {baseline_r2:.2%})

---

## Deney SonuÃ§larÄ±

| Deney | RÂ² Score | MAE | Ä°yileÅŸme |
|-------|----------|-----|----------|
"""
    
    for result in results:
        improvement = ((result['r2'] - baseline_r2) / baseline_r2) * 100
        report += f"| {result['name']} | {result['r2']:.4f} | {result['mae']:.4f} | +{improvement:.1f}% |\n"
    
    report += f"""
---

## En Ä°yi Model: {best_result['name']}

- **RÂ² Score:** {best_result['r2']:.4f} ({best_result['r2']:.2%})
- **MAE:** {best_result['mae']:.4f}
- **Ä°yileÅŸme:** +{((best_result['r2'] - baseline_r2) / baseline_r2) * 100:.1f}%

### Performans DeÄŸerlendirmesi

"""
    
    if best_result['r2'] >= 0.50:
        report += "âœ… **HEDEF ULAÅžILDI!** %50 RÂ² hedefine ulaÅŸÄ±ldÄ± veya aÅŸÄ±ldÄ±.\n\n"
    elif best_result['r2'] >= 0.45:
        report += "âš¡ **HEDEF YAKLAÅžILDI!** %50 hedefine Ã§ok yaklaÅŸÄ±ldÄ±. Ek iyileÅŸtirmelerle hedef ulaÅŸÄ±labilir.\n\n"
    elif best_result['r2'] >= 0.40:
        report += "ðŸ“ˆ **Ã–NEMLI Ä°YÄ°LEÅžME!** Baseline'den Ã¶nemli iyileÅŸme saÄŸlandÄ±. %50 hedefi iÃ§in ek feature'lar gerekli.\n\n"
    else:
        report += "ðŸ“Š **SINIRLI Ä°YÄ°LEÅžME.** Mevcut feature'larla %50 hedefi zor gÃ¶rÃ¼nÃ¼yor. Yeni veri kaynaklarÄ± gerekli.\n\n"
    
    report += f"""
![Improvement Comparison](04_improvement_comparison.png)

---

## Ã–neriler

### KÄ±sa Vadeli (Hemen Uygulanabilir)

1. **En iyi modeli kullan:** {best_result['name']} modelini production'a al
2. **Ensemble dene:** Birden fazla modelin ortalamasÄ± daha stabil sonuÃ§lar verebilir
3. **Cross-validation:** K-fold ile performansÄ± doÄŸrula

### Orta Vadeli (Yeni Feature'lar)

1. **Dava metinleri:** NLP ile suÃ§ tanÄ±mlarÄ±nÄ± analiz et
2. **Hakim geÃ§miÅŸi:** Hakim bazlÄ± istatistikler ekle
3. **Temporal patterns:** YÄ±l/mevsim etkilerini modelle

### Uzun Vadeli (DÄ±ÅŸ Veri)

1. **Mahkeme kayÄ±tlarÄ±:** DuruÅŸma sÃ¼releri, tanÄ±k sayÄ±larÄ±
2. **Sosyoekonomik:** BÃ¶lgesel ekonomik gÃ¶stergeler
3. **SuÃ§lu profili:** EÄŸitim, istihdam durumu

---

**HazÄ±rlayan:** Antigravity AI  
**Tarih:** {pd.Timestamp.now().strftime('%Y-%m-%d')}  
**Versiyon:** 1.0
"""
    
    # Raporu kaydet
    report_path = OUTPUT_DIR / 'improvement_results.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… Ä°yileÅŸtirme raporu oluÅŸturuldu: {report_path}")


def main():
    """Ana fonksiyon"""
    print("="*60)
    print("ðŸš€ HIGH SEVERITY MODEL IMPROVEMENT EXPERIMENTS")
    print("="*60)
    
    # 1. Veri yÃ¼kle
    df_high = load_high_severity_data()
    
    # 2. Advanced features ekle
    df_high = create_advanced_features(df_high)
    
    # 3. Features hazÄ±rla
    X, available_features, cat_features = prepare_features(df_high)
    y = np.log1p(df_high['jail'])
    
    print(f"\nðŸ“Š Final Feature Count: {len(available_features)}")
    print(f"ðŸ“Š Categorical Features: {len(cat_features)}")
    
    # 4. Deneyleri Ã§alÄ±ÅŸtÄ±r
    results = []
    
    results.append(experiment_1_baseline(X, y, cat_features))
    results.append(experiment_2_deep_trees(X, y, cat_features))
    results.append(experiment_3_more_iterations(X, y, cat_features))
    results.append(experiment_4_ensemble(X, y, cat_features))
    results.append(experiment_5_quantile_loss(X, y, cat_features))
    results.append(experiment_6_advanced_features_only(X, y, cat_features))
    
    # 5. SonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±r
    best_result = compare_results(results)
    
    # 6. En iyi modeli kaydet
    save_best_model(best_result, X, y, cat_features, available_features)
    
    # 7. Rapor oluÅŸtur
    generate_improvement_report(results, best_result)
    
    print("\n" + "="*60)
    print("âœ… TÃœM DENEYLER TAMAMLANDI!")
    print("="*60)
    print(f"\nðŸ“‚ Ã‡Ä±ktÄ±lar: {OUTPUT_DIR}")
    print(f"   â€¢ improvement_results.md")
    print(f"   â€¢ 04_improvement_comparison.png")
    print(f"\nðŸ“‚ Model: {MODEL_DIR}")
    print(f"   â€¢ model_high_v2_improved.cbm (EN Ä°YÄ° MODEL)")


if __name__ == "__main__":
    main()
